{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laborator 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de regresie\n",
    "\n",
    "Folositi urmatoarele seturi de date:\n",
    "1. [CPU Computer Hardware](https://archive.ics.uci.edu/ml/datasets/Computer+Hardware); excludeti din dataset coloanele: vendor name, model name, estimated relative performance; se va estima coloana \"published relative performance\".\n",
    "1. [Boston Housing](http://archive.ics.uci.edu/ml/machine-learning-databases/housing/)\n",
    "1. [Wisconsin Breast Cancer](http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html); cautati in panelul din stanga Wisconsin Breast Cancer si urmati pasii din \"My personal Notes\"\n",
    "1. [Communities and Crime](http://archive.ics.uci.edu/ml/datasets/communities+and+crime); stergeti primele 5 dimensiuni si trasaturile cu missing values.\n",
    "\n",
    "Pentru fiecare set de date aplicati minim 5 modele de regresie din scikit learn. Pentru fiecare raportati: mean absolute error, mean squared error, median absolute error - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) - folosind 5 fold cross validation. Valorile hiperparametrilor trebuie cautate cu grid search (cv=3)  si random search (n_iter dat de voi). Metrica folosita pentru cautarea hiperparametrilor va fi mean squared error. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare; indicatie: puteti folosi metoda `cross_validate` cu parametrul `return_train_score=True`, iar ca model un obiect de tip `GridSearchCV` sau `RandomizedSearchCV`.\n",
    "\n",
    "Rezultatele vor fi trecute intr-un dataframe. Intr-o stare intermediara, valorile vor fi calculate cu semnul minus: din motive de implementare, biblioteca sklearn transforma scorurile in numere negative; a se vedea imaginea de mai jos:\n",
    "\n",
    "![intermediate report](./images/cpu_intermediate_blurred.png)\n",
    "\n",
    "\n",
    "Valorile vor fi aduse la interval pozitiv, apoi vor fi marcate cele maxime si minime; orientativ, se poate folosi imaginea de mai jos, reprezentand dataframe afisat in notebook; puteti folosi alte variante de styling pe dataframe precum la https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html#.  \n",
    "\n",
    "Se va crea un raport final in format HTML sau PDF - fisier(e) separat(e). Raportul trebuie sa contina minimal: numele setului de date si obiectul dataframe; preferabil sa se pastreze marcajul de culori realizat in notebook.\n",
    "\n",
    "![report](./images/cpu_results_blurred.png)\n",
    "\n",
    "Notare:\n",
    "1. Se acorda 20 de puncte din oficiu.\n",
    "1. Optimizare si cuantificare de performanta a modelelor: 3 puncte pentru fiecare combinatie set de date + model = 60 de puncte\n",
    "1. Documentare modele: numar modele * 2 puncte = 10 puncte. Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Puteti face o sectiune separata cu documentarea algoritmilor. Fiecare model trebuie sa aiba o descriere de minim 20 de randuri, minim o imagine asociata si minim 2 referinte bibliografice.\n",
    "1. 10 puncte: export in format HTML sau PDF.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notare:* laboratorul va fi salvat in repository-ul de github si prezentat in saptamana 6-10 mai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:57:36.421497Z",
     "start_time": "2019-05-08T06:57:27.092669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV,cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "print('Pandas version:', pd.__version__) #Pandas version: 0.23.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and preparing the data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CPU Computer Hardware](https://archive.ics.uci.edu/ml/datasets/Computer+Hardware); excludeti din dataset coloanele: vendor name, model name, estimated relative performance; se va estima coloana \"published relative performance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:57:51.751447Z",
     "start_time": "2019-05-08T06:57:51.720212Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_machine = pd.read_csv(\"data/machine.data\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:57:52.032677Z",
     "start_time": "2019-05-08T06:57:51.954556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adviser</td>\n",
       "      <td>32/60</td>\n",
       "      <td>125</td>\n",
       "      <td>256</td>\n",
       "      <td>6000</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>269</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7a</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7b</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>172</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7c</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1    2     3      4    5   6    7    8    9\n",
       "0  adviser    32/60  125   256   6000  256  16  128  198  199\n",
       "1   amdahl   470v/7   29  8000  32000   32   8   32  269  253\n",
       "2   amdahl  470v/7a   29  8000  32000   32   8   32  220  253\n",
       "3   amdahl  470v/7b   29  8000  32000   32   8   32  172  253\n",
       "4   amdahl  470v/7c   29  8000  16000   32   8   16  132  132"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_machine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:57:52.220161Z",
     "start_time": "2019-05-08T06:57:52.157670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>256</td>\n",
       "      <td>6000</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     2     3      4    5   6    7    8\n",
       "0  125   256   6000  256  16  128  198\n",
       "1   29  8000  32000   32   8   32  269\n",
       "2   29  8000  32000   32   8   32  220\n",
       "3   29  8000  32000   32   8   32  172\n",
       "4   29  8000  16000   32   8   16  132"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_machine = dataframe_machine.drop([0, 1, 9], axis = 1)\n",
    "dataframe_machine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:57:54.313757Z",
     "start_time": "2019-05-08T06:57:54.282506Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_machine_X = dataframe_machine.values[:, :-1]\n",
    "dataframe_machine_Y = dataframe_machine.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Boston Housing](http://archive.ics.uci.edu/ml/machine-learning-databases/housing/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:57:54.641868Z",
     "start_time": "2019-05-08T06:57:54.579368Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_housing = pd.read_csv(\"data/housing.data\", header = None, sep=r\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:57:54.766862Z",
     "start_time": "2019-05-08T06:57:54.735599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2   3      4      5     6       7   8      9     10  \\\n",
       "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "2  0.02729   0.0  7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
       "3  0.03237   0.0  2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
       "4  0.06905   0.0  2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
       "\n",
       "       11    12    13  \n",
       "0  396.90  4.98  24.0  \n",
       "1  396.90  9.14  21.6  \n",
       "2  392.83  4.03  34.7  \n",
       "3  394.63  2.94  33.4  \n",
       "4  396.90  5.33  36.2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:57:54.923086Z",
     "start_time": "2019-05-08T06:57:54.907474Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_housing_X = dataframe_housing.values[:, :-1]\n",
    "dataframe_housing_Y = dataframe_housing.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Wisconsin Breast Cancer](http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html); cautati in panelul din stanga Wisconsin Breast Cancer si urmati pasii din \"My personal Notes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:57:55.657458Z",
     "start_time": "2019-05-08T06:57:55.594923Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_wpbc = pd.read_csv(\"data/r_wpbc.data\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:57:57.469380Z",
     "start_time": "2019-05-08T06:57:57.422507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>18.02</td>\n",
       "      <td>27.60</td>\n",
       "      <td>117.50</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.09489</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>0.07055</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>...</td>\n",
       "      <td>139.70</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08113</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>21.37</td>\n",
       "      <td>17.44</td>\n",
       "      <td>137.50</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.08180</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>...</td>\n",
       "      <td>159.10</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>0.1188</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.09067</td>\n",
       "      <td>2.5</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.2839</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>3.5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2       3       4        5       6       7        8       9   \\\n",
       "0   5  18.02  27.60  117.50  1013.0  0.09489  0.1036  0.1086  0.07055  0.1865   \n",
       "1   2  17.99  10.38  122.80  1001.0  0.11840  0.2776  0.3001  0.14710  0.2419   \n",
       "2   0  21.37  17.44  137.50  1373.0  0.08836  0.1189  0.1255  0.08180  0.2333   \n",
       "3   0  11.42  20.38   77.58   386.1  0.14250  0.2839  0.2414  0.10520  0.2597   \n",
       "4   0  20.29  14.34  135.10  1297.0  0.10030  0.1328  0.1980  0.10430  0.1809   \n",
       "\n",
       "   ...      23      24      25      26      27      28      29       30   31  \\\n",
       "0  ...  139.70  1436.0  0.1195  0.1926  0.3140  0.1170  0.2677  0.08113  5.0   \n",
       "1  ...  184.60  2019.0  0.1622  0.6656  0.7119  0.2654  0.4601  0.11890  3.0   \n",
       "2  ...  159.10  1949.0  0.1188  0.3449  0.3414  0.2032  0.4334  0.09067  2.5   \n",
       "3  ...   98.87   567.7  0.2098  0.8663  0.6869  0.2575  0.6638  0.17300  2.0   \n",
       "4  ...  152.20  1575.0  0.1374  0.2050  0.4000  0.1625  0.2364  0.07678  3.5   \n",
       "\n",
       "    32  \n",
       "0   31  \n",
       "1   61  \n",
       "2  116  \n",
       "3  123  \n",
       "4   27  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_wpbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:57:57.844351Z",
     "start_time": "2019-05-08T06:57:57.828713Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_wpbc_X = dataframe_wpbc.values[:, :-1]\n",
    "dataframe_wpbc_Y = dataframe_wpbc.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Communities and Crime](http://archive.ics.uci.edu/ml/datasets/communities+and+crime); stergeti primele 5 dimensiuni si trasaturile cu missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:57:59.906721Z",
     "start_time": "2019-05-08T06:57:59.766135Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_communities = pd.read_csv(\"data/communities.data\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:57:59.969177Z",
     "start_time": "2019-05-08T06:57:59.937947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>81440</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>95</td>\n",
       "      <td>6096</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1      2                    3    4     5     6     7     8     9    \\\n",
       "0    8   ?      ?         Lakewoodcity    1  0.19  0.33  0.02  0.90  0.12   \n",
       "1   53   ?      ?          Tukwilacity    1  0.00  0.16  0.12  0.74  0.45   \n",
       "2   24   ?      ?         Aberdeentown    1  0.00  0.42  0.49  0.56  0.17   \n",
       "3   34   5  81440  Willingborotownship    1  0.04  0.77  1.00  0.08  0.12   \n",
       "4   42  95   6096    Bethlehemtownship    1  0.01  0.55  0.02  0.95  0.09   \n",
       "\n",
       "   ...   118   119   120   121   122  123  124   125   126   127  \n",
       "0  ...  0.12  0.26  0.20  0.06  0.04  0.9  0.5  0.32  0.14  0.20  \n",
       "1  ...  0.02  0.12  0.45     ?     ?    ?    ?  0.00     ?  0.67  \n",
       "2  ...  0.01  0.21  0.02     ?     ?    ?    ?  0.00     ?  0.43  \n",
       "3  ...  0.02  0.39  0.28     ?     ?    ?    ?  0.00     ?  0.12  \n",
       "4  ...  0.04  0.09  0.02     ?     ?    ?    ?  0.00     ?  0.03  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_communities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:58:00.297291Z",
     "start_time": "2019-05-08T06:58:00.094183Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>125</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    5     6     7     8     9     10    11    12    13    14   ...   96   \\\n",
       "0  0.19  0.33  0.02  0.90  0.12  0.17  0.34  0.47  0.29  0.32  ...  0.12   \n",
       "1  0.00  0.16  0.12  0.74  0.45  0.07  0.26  0.59  0.35  0.27  ...  0.21   \n",
       "2  0.00  0.42  0.49  0.56  0.17  0.04  0.39  0.47  0.28  0.32  ...  0.14   \n",
       "3  0.04  0.77  1.00  0.08  0.12  0.10  0.51  0.50  0.34  0.21  ...  0.19   \n",
       "4  0.01  0.55  0.02  0.95  0.09  0.05  0.38  0.38  0.23  0.36  ...  0.11   \n",
       "\n",
       "    97    98    99    100   118   119   120   125   127  \n",
       "0  0.42  0.50  0.51  0.64  0.12  0.26  0.20  0.32  0.20  \n",
       "1  0.50  0.34  0.60  0.52  0.02  0.12  0.45  0.00  0.67  \n",
       "2  0.49  0.54  0.67  0.56  0.01  0.21  0.02  0.00  0.43  \n",
       "3  0.30  0.73  0.64  0.65  0.02  0.39  0.28  0.00  0.12  \n",
       "4  0.72  0.64  0.61  0.53  0.04  0.09  0.02  0.00  0.03  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_communities = dataframe_communities.drop([0,1,2,3,4], axis=1)\n",
    "missing_index = dataframe_communities.columns[(dataframe_communities == '?').any()].tolist()\n",
    "dataframe_communities = dataframe_communities.drop(missing_index, axis=1)\n",
    "dataframe_communities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:58:00.312916Z",
     "start_time": "2019-05-08T06:58:00.297291Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_communities_X = dataframe_communities.values[:, :-1]\n",
    "dataframe_communities_Y = dataframe_communities.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the regression models and auxiliary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:58:07.724463Z",
     "start_time": "2019-05-08T06:58:07.708891Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "columns = ['Model', 'Search', 'train_mean_absolute_error', 'train_mean_squared_error',\n",
    "            'train_median_absolute_error', 'test_mean_absolute_error', 'test_mean_squared_error', \n",
    "            'test_median_absolute_error']\n",
    "subset = ['train_mean_absolute_error', 'train_mean_squared_error', 'train_median_absolute_error',\n",
    "            'test_mean_absolute_error', 'test_mean_squared_error', 'test_median_absolute_error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlighting functions for pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:58:08.036925Z",
     "start_time": "2019-05-08T06:58:08.021326Z"
    }
   },
   "outputs": [],
   "source": [
    "def highlight_max(s)-> pd.DataFrame:\n",
    "    '''\n",
    "    Colors the max cells in green, given a pandas DataFrame object.\n",
    "    param:  s: the pandas DataFrame\n",
    "    return: colored pandas DataFrame\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: red' if v else '' for v in is_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:58:08.208787Z",
     "start_time": "2019-05-08T06:58:08.193168Z"
    }
   },
   "outputs": [],
   "source": [
    "def highlight_min(s)-> pd.DataFrame:\n",
    "    '''\n",
    "    Colors the min cells in red, given a pandas DataFrame object.\n",
    "    param:  s: the pandas DataFrame;\n",
    "    return: colored pandas DataFrame\n",
    "    '''\n",
    "    is_min = s == s.min()\n",
    "    return ['background-color: green' if v else '' for v in is_min]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors function, mean square, mean absolute, median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:58:16.438235Z",
     "start_time": "2019-05-08T06:58:16.407040Z"
    }
   },
   "outputs": [],
   "source": [
    "def errors(model, x_train :np.ndarray, x_test :np.ndarray, y_train :np.ndarray, y_test: np.ndarray) -> list:\n",
    "    '''\n",
    "    Calculates the 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_median_absolute_error' on both train and\n",
    "    test sets with cross validation, having the model as a param.\n",
    "    param:   model: sklearn model, the given model that is needed for cross_validation;\n",
    "             x_train: the train set for the model;\n",
    "             x_test: the test set for the model;\n",
    "             y_train: the verification for the train set;\n",
    "             y_test: the verification for the test set;\n",
    "    return:  list with the errors multyplied by -1 to be positive.\n",
    "    '''\n",
    "    train_neg_mean_absolute_error = cross_val_score(model, x_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "    train_neg_mean_squared_error = cross_val_score(model, x_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    train_neg_median_absolute_error = cross_val_score(model, x_train, y_train, cv=5, scoring='neg_median_absolute_error')\n",
    "    test_neg_mean_absolute_error = cross_val_score(model, x_test, y_test, cv=5, scoring='neg_mean_absolute_error')\n",
    "    test_neg_mean_squared_error = cross_val_score(model, x_test, y_test, cv=5, scoring='neg_mean_squared_error')\n",
    "    test_neg_median_absolute_error = cross_val_score(model, x_test, y_test, cv=5, scoring='neg_median_absolute_error')\n",
    "    return [train_neg_mean_absolute_error.mean()*-1, train_neg_mean_squared_error.mean()*-1, \n",
    "           train_neg_median_absolute_error.mean()*-1, test_neg_mean_absolute_error.mean()*-1, \n",
    "           test_neg_mean_squared_error.mean()*-1, test_neg_median_absolute_error.mean()*-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search and random search functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:58:33.018225Z",
     "start_time": "2019-05-08T06:58:33.002600Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_random(parameters: dict, model, x_train: np.ndarray, x_test: np.ndarray, y_train: np.ndarray, y_test: np.ndarray) -> list:\n",
    "    '''\n",
    "    Dose the random cross validation search, it returns the best parameter found and than, the model goes to the error\n",
    "    function to see how well it has done.\n",
    "    param:   parameters: dictionary type, has the all the alternatives to the hyperparameters, the actual subject of\n",
    "                         this function\n",
    "             model: sklearn model, the given model that is needed for cross_validation;\n",
    "             x_train: the train set for the model;\n",
    "             x_test: the test set for the model;\n",
    "             y_train: the verification for the train set;\n",
    "             y_test: the verification for the test set;\n",
    "    return:  list with erros returned by 'errors' function and the appropiate name.\n",
    "    '''\n",
    "    randomized_search = RandomizedSearchCV(estimator = model, param_distributions = parameters, scoring='neg_mean_squared_error', cv=3, return_train_score=True, iid=False)\n",
    "    randomized_search.fit(x_train, y_train)\n",
    "    return ['Random Search'] + errors(randomized_search, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:58:44.285505Z",
     "start_time": "2019-05-08T06:58:44.269895Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_grid(parameters: dict, model, x_train: np.ndarray, x_test: np.ndarray, y_train: np.ndarray, y_test: np.ndarray) -> list:\n",
    "    '''\n",
    "    Dose the grid cross validation search, it returns the best parameter found and than, the model goes to the error\n",
    "    function to see how well it has done.\n",
    "    param:   parameters: dictionary type, has the all the alternatives to the hyperparameters, the actual subject of\n",
    "                         this function\n",
    "             model: sklearn model, the given model that is needed for cross_validation;\n",
    "             x_train: the train set for the model;\n",
    "             x_test: the test set for the model;\n",
    "             y_train: the verification for the train set;\n",
    "             y_test: the verification for the test set;\n",
    "    return:  list with erros returned by 'errors' function and the appropiate name.\n",
    "    '''\n",
    "    grid_search = GridSearchCV(estimator = model, param_grid = parameters, scoring='neg_mean_squared_error', cv=3, return_train_score=True, iid=False)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    return ['Grid Search'] + errors(grid_search, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model functions, KNN, SVR, Random Forest, Tree, GaussianProcessRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:58:48.430434Z",
     "start_time": "2019-05-08T06:58:48.399174Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_knn(parameters: dict, x_train: np.ndarray, y_train: np.ndarray, x_test: np.ndarray, y_test: np.ndarray) -> None:\n",
    "    '''\n",
    "    Initialization for KNeighborsRegressor model and starting the grid and random search.\n",
    "    Appends into a list the results\n",
    "    '''\n",
    "    model = KNeighborsRegressor()\n",
    "    data.append(['KNN'] + search_grid(parameters, model, x_train, x_test, y_train, y_test))\n",
    "    data.append(['KNN'] + search_random(parameters, model, x_train, x_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:58:49.039749Z",
     "start_time": "2019-05-08T06:58:49.024157Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_svc(parameters: dict, x_train: np.ndarray, y_train: np.ndarray, x_test: np.ndarray, y_test: np.ndarray) -> None:\n",
    "    '''\n",
    "    Initialization for SVR model and starting the grid and random search.\n",
    "    Appends into a list the results\n",
    "    '''\n",
    "    model = SVR()\n",
    "    data.append(['SVR'] + search_grid(parameters, model, x_train, x_test, y_train, y_test))\n",
    "    data.append(['SVR'] + search_random(parameters, model, x_train, x_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:58:49.555350Z",
     "start_time": "2019-05-08T06:58:49.539725Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_forest(parameters: dict, x_train: np.ndarray, y_train: np.ndarray, x_test: np.ndarray, y_test: np.ndarray) -> None:\n",
    "    '''\n",
    "    Initialization for RandomForestRegressor model and starting the grid and random search.\n",
    "    Appends into a list the results\n",
    "    '''\n",
    "    model = RandomForestRegressor()\n",
    "    data.append(['Forest'] + search_grid(parameters, model, x_train, x_test, y_train, y_test))\n",
    "    data.append(['Forest'] + search_random(parameters, model, x_train, x_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:58:51.289581Z",
     "start_time": "2019-05-08T06:58:51.274023Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_tree(parameters: dict, x_train: np.ndarray, y_train: np.ndarray, x_test: np.ndarray, y_test: np.ndarray) -> None:\n",
    "    '''\n",
    "    Initialization for DecisionTreeRegressor model and starting the grid and random search.\n",
    "    Appends into a list the results\n",
    "    '''\n",
    "    model = DecisionTreeRegressor()\n",
    "    data.append(['Tree'] + search_grid(parameters, model, x_train, x_test, y_train, y_test))\n",
    "    data.append(['Tree'] + search_random(parameters, model, x_train, x_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianProcessRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:58:51.898925Z",
     "start_time": "2019-05-08T06:58:51.867691Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_GaussianProcessRegressor(parameters: dict, x_train: np.ndarray, y_train: np.ndarray, x_test: np.ndarray, y_test: np.ndarray) -> None:\n",
    "    '''\n",
    "    Initialization for GaussianProcessRegressor model and starting the grid and random search.\n",
    "    Appends into a list the results\n",
    "    '''\n",
    "    model = GaussianProcessRegressor()\n",
    "    data.append(['GaussianProcessRegressor'] + (search_grid(parameters, model, x_train, x_test, y_train, y_test)))\n",
    "    data.append(['GaussianProcessRegressor'] + (search_random(parameters, model, x_train, x_test, y_train, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The main function to deliver the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T06:59:12.042781Z",
     "start_time": "2019-05-08T06:59:12.011533Z"
    }
   },
   "outputs": [],
   "source": [
    "def search(x: np.ndarray, y: np.ndarray, name: str) -> None:\n",
    "    '''\n",
    "    Creates a pandas DataFrame object in witch it stores all the results that are needed. Exports the dataframe into a \n",
    "    HTML file.\n",
    "    param:   x: the data set for the model;\n",
    "             y: the labels set for the model;\n",
    "             name: the name of export HTML file\n",
    "    return:  None\n",
    "    '''\n",
    "    data.clear()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1/3)\n",
    "    \n",
    "    parameters_gaussian = {'alpha': list([0.0000000000001, 0.000000000001, 0.00000000001, 0.0000000001, 0.000000001, 0.00000001, 0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0])}\n",
    "    parameters_tree = {'random_state': list([1, 50, 100, 200, 300, 333, 500, 700, 1000, 2000, 3000, 10000])}\n",
    "    parameters_forest = {'n_estimators': list(range(1,13))}\n",
    "    parameters_svr = {'gamma' : list(['auto']), 'C': list([0.1, 0.2, 0.3, 0.5, 0.7, 1.0, 2.0, 3.0, 4.0, 5.0, 10.0])}\n",
    "    parameters_knn = {'n_neighbors': list(range(1,12)), 'p': [1, 2, 3, 4.7]} \n",
    "    \n",
    "    search_knn(parameters_knn, x_train, y_train, x_test, y_test)\n",
    "    search_svc(parameters_svr, x_train, y_train, x_test, y_test)\n",
    "    search_forest(parameters_forest, x_train, y_train, x_test, y_test)\n",
    "    search_tree(parameters_tree, x_train, y_train, x_test, y_test)\n",
    "    search_GaussianProcessRegressor(parameters_gaussian, x_train, y_train, x_test, y_test)\n",
    "    \n",
    "    data_frame = pd.DataFrame(data, columns=columns)\n",
    "    data_frame = data_frame.style.apply(highlight_max, subset=subset).apply(highlight_min, subset=subset)\n",
    "    f=open(f\"{name}.html\",\"w\")\n",
    "    f.write(data_frame.render())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feeding the models with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T07:00:39.732811Z",
     "start_time": "2019-05-08T06:59:14.783832Z"
    }
   },
   "outputs": [],
   "source": [
    "search(dataframe_housing_X, dataframe_housing_Y, \"housing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T07:01:30.462269Z",
     "start_time": "2019-05-08T07:00:57.218492Z"
    }
   },
   "outputs": [],
   "source": [
    "search(dataframe_machine_X, dataframe_machine_Y, \"machine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wpbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T07:03:15.096452Z",
     "start_time": "2019-05-08T07:02:30.254607Z"
    }
   },
   "outputs": [],
   "source": [
    "search(dataframe_wpbc_X, dataframe_wpbc_Y, \"wpbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T13:13:44.834906Z",
     "start_time": "2019-05-01T12:15:18.176187Z"
    }
   },
   "outputs": [],
   "source": [
    "search(dataframe_communities_X, dataframe_communities_Y, \"communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Nearest Neighbors Regression (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors Regression este un algoritm de invatare nesupervizata, conceput pentru a fi utilizat în probleme care implică segmentarea pieței, detectarea fraudei, motoare de recomandare, gruparea paginilor web prin similitudine.\n",
    "\n",
    "În KNN, K reprezinta numărul de vecini apropiați. Numărul de vecini este factorul decisiv de bază. K este, în general, un număr impar dacă numărul de clase este 2. Când K = 1 algoritmul este cunoscut ca nearest neighbor. Acesta este cel mai simplu caz. Sa presupunem că P1 este un punct pentru care trebuie sa ii prezicem eticheta. Mai întâi, găsim cel mai apropiat punct de P1 și atribuim eticheta acestuia lui P1.\n",
    "\n",
    "![report](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/Knn_k1_z96jba.png)\n",
    "\n",
    "Cand K > 1 algoritmul cauta K cei mai apropiati vecini de punctul P1 si eticheta lui este bazata pe votul majoritatii vecinilor. Pentru a gasi cele mai apropiate puncte similare de P1, trebuie calculate distantele dintre puncte folosind metrici precum distanta Euclidiana, distanta Hamming, distanta Manhattan si distanta Minkowski. KNN are urmatoarele etape de baza:\n",
    "\n",
    "1. Calculculeaza distanta\n",
    "2. Gaseste cel mai apropiat vecin\n",
    "3. Voteaza pentru eticheta\n",
    "\n",
    "![report](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/KNN_final1_ibdm8a.png)\n",
    "\n",
    "Nu este nevoie de învățare sau instruire a modelului și a tuturor punctelor de date folosite la momentul predicției. Algoritmul  așteaptă până în ultimul minut pentru a clasifica orice punct. Acesta stochează doar setul de date de antrenament și așteaptă până când clasificarea trebuie să se desfășoare. Doar atunci când vede setul de testare, efectuează generalizarea pentru a clasifica setul de testare bazat pe similitudinea cu setul de antrenament stocat. Spre deosebire de alte metodele de învățare, algoritmul face mai puțini pasi în faza de formare și mai multă muncă în faza de testare pentru a face o clasificare.\n",
    "\n",
    "K-nearest neighbors regression folosește ponderi uniforme, adică fiecare punct al unei clase contribuie uniform la identificarea unui punct de interogare. În anumite circumstanțe, poate fi avantajos să se analizeze puntele astfel încât punctele din apropiere să contribuie mai mult la regresie decât punctele îndepărtate. Acest lucru poate fi realizat prin intermediul cuvântului cheie ponderi. Valoarea implicită, weights = \"uniform\", atribuie ponderi egale tuturor punctelor. weights = 'distance' atribuie ponderi proporționale cu inversul distanței de la punctul de interogare. Alternativ, poate fi furnizată o funcție definită de utilizator a distanței, care va fi utilizată pentru a calcula ponderile.\n",
    "\n",
    "Cercetările au arătat că nici un număr optim de vecini nu se potrivește cu toate tipurile de seturi de date. Fiecare set de date are propriile cerințe. În cazul unui număr mic de vecini, zgomotul va avea o influență mai mare asupra rezultatului, și un număr mare de vecini îl face costisitor din punct de vedere computațional. Cercetările au arătat, de asemenea, că o cantitate mică de vecini este cea mai flexibilă. În general, se alege K un număr impar dacă numărul de clase este par.\n",
    "\n",
    "\n",
    "Resurse:\n",
    "1. https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn\n",
    "2. https://analyticstraining.com/popular-regression-algorithms-ml/\n",
    "3. https://scikit-learn.org/stable/modules/neighbors.html#regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Regression este utilizat în machine learning pentru a rezolva problemele legate de segmentarea imaginii, piața bursieră, clasificarea textului și științele biologice.\n",
    "\n",
    "Support Vector Machines este o clasa foarte specifica de algoritmi, caracterizata prin folosirea kernelurilor, absenta minimelor locale, dispersie a solutiei si controlul capacitatii obtinute prin actiunea asupra marginilor sau pe numarul de support vectors etc.\n",
    "\n",
    "SVR folosește aceleași principii ca SVM pentru clasificare, cu doar câteva diferențe minore. În primul rând, deoarece output-ul este un număr real, devine foarte dificilă prezicerea informațiilor care au posibilități infinite. În cazul regresiei, o marjă de toleranță (epsilon) este stabilită în apropierea SVM care ar fi solicitat deja din problemă. Cu toate acestea, ideea principală este întotdeauna aceeași: pentru a minimiza eroarea se individualizeaza hiperplanul care maximizează marja, având în vedere că o parte din eroare este tolerată. \n",
    "\n",
    "*Kernel-ul este funcția utilizată pentru a mapa date dimensionale inferioare într-o valoare dimensională superioară.\n",
    "\n",
    "*Hyper Plane in SVR este definit ca linia care ne va ajuta să anticipăm valoarea continuă sau valoarea țintă.\n",
    "\n",
    "*Support Vectors sunt punctele care se află cel mai aproape de limită. Distanța punctelor este minimă.\n",
    "\n",
    "*Boundary line: în SVM există alte două linii decât Hyper Plane care creează o marjă. Support Vectors pot fi pe Boundary line sau în afara ei. Această linie de separare separă cele două clase. În SVR, conceptul este același.\n",
    "\n",
    "Exista 2 tipuri de SVR:\n",
    "1. Linear\n",
    "2. Non-Linear\n",
    "\n",
    "![raport](https://www.saedsayad.com/images/SVR_5.png)\n",
    "\n",
    "A se vedea modul în care toate punctele se află între boundaryes lines. Obiectivul nostru este ca atunci când ne mișcăm cu SVR sa luam în considerare punctele care se află între boundaryes lines. Linia de potrivire cea mai bună este linia hyperplane care are un număr maxim de puncte.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/freeze/1*rs0EfF8RPVpgA-EfgAq85g.jpeg)\n",
    "\n",
    "Modelul produs de Support Vector Regression depinde numai de un subset de date de antrenament, deoarece funcția de cost pentru construirea modelului ignoră toate datele de antrenament apropiate de predicția modelului.\n",
    "\n",
    "Resurse:\n",
    "1. https://medium.com/coinmonks/support-vector-regression-or-svr-8eb3acf6d0ff\n",
    "2. https://analyticstraining.com/popular-regression-algorithms-ml/\n",
    "3. https://www.saedsayad.com/support_vector_machine_reg.htm\n",
    "4. https://scikit-learn.org/stable/modules/svm.html#svm-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor este utilizat într-o mulțime de domenii diferite, cum ar fi sectorul bancar, bursa, medicina și comerțul electronic. În sectorul bancar se utilizează, de exemplu, pentru a detecta clienții care vor folosi serviciile băncii mai frecvent decât alții și își vor rambursa datoriile în timp. În acest domeniu, este folosit și pentru detectarea clienților de fraudă care doresc să înșele banca. În finanțe, este folosit pentru a determina comportamentul stocului în viitor. În domeniul sănătății este folosit pentru a identifica combinația corectă a componentelor din medicină și pentru a analiza istoricul medical al pacientului pentru a identifica bolile. Și, în sfârșit, in comerțul electronic este utilizat pentru a determina dacă un client va dori de fapt produsul sau nu.\n",
    "\n",
    "Random forest este o tehnică de ansamblu capabilă să efectueze atât sarcini de regresie, cât și sarcini de clasificare, folosind mai mulți copaci de decizie și o tehnică numită Bootstrap Aggregation, cunoscută în mod obișnuit ca \"bagging\". Bagging-ul, în metoda Random Forest, implică instruirea fiecărui arbore al deciziilor pe un eșantion de date diferit, unde prelevarea de probe se face cu înlocuirea.\n",
    "\n",
    "Ideea de bază din spatele acestui algoritm este combinarea mai multor arbori de decizie în determinarea output-ului final, în loc să se bazeze pe arborii decizionali individuali.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1200/1*i0o8mjFfCn-uD79-F1Cqkw.png)\n",
    "\n",
    "Random forest adaugă o randomizare suplimentară modelului, în timp ce crește copacii. În loc să căutăm cea mai importantă caracteristică în timp ce divizăm un nod, acesta caută cea mai bună caracteristică dintr-un subset aleatoriu de caracteristici. Aceasta are ca rezultat o diversitate largă care, în general, are ca rezultat un model mai bun.\n",
    "\n",
    "Prin urmare, în random forest, doar un subset aleator al caracteristicilor este luat în considerare prin algoritmul de împărțire a unui nod. Se pot face arbori mai aleatorii, folosind în plus praguri aleatorii pentru fiecare caracteristică, în loc să căutați cele mai bune praguri posibile (cum face un decision tree).\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*9kACduxnce_JdTrftM_bsA.gif)\n",
    "\n",
    "Resuse:\n",
    "1. https://medium.com/datadriveninvestor/random-forest-regression-9871bc9a25eb\n",
    "2. https://towardsdatascience.com/the-random-forest-algorithm-d457d499ffcd\n",
    "3. https://medium.com/@williamkoehrsen/random-forest-simple-explanation-377895a60d2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree este un model intuitiv în care se traversează cate o data ramurile copacului și selectează următoarea ramură pentru a merge în jos pe baza unei decizii la un nod. Inducția copacilor este sarcina de a lua un set de instanțe de formare ca intrări, de a decide care atribute sunt cel mai bine să se împartă, de a împărți setul de date și de a repeta pe seturile de date divizate rezultate până când toate instanțele de formare sunt clasificate. \n",
    "\n",
    "În timpul construirii copacului, scopul este de a se împărți pe atributele care creează cele mai pure noduri copil posibile, ceea ce ar reduce la minimum numărul de împărțiri care ar trebui făcute pentru a clasifica toate instanțele din setul nostru de date. Puritatea este măsurată prin conceptul de câștig de informații, care se referă la cât de mult ar trebui să fie cunoscuta o instanță anterior nevăzută pentru a fi clasificată corespunzător. \n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*KOg1s4s4mg44q_6Oi5D-mQ.png)\n",
    "\n",
    "În practică, acest lucru se măsoară prin compararea entropiei sau a cantității de informații necesare pentru a clasifica o singură instanță a unei partiții de date curente la cantitatea de informații pentru a clasifica o singură instanță în cazul în care divizia de seturi de date curente urma să fie mai mult împărțită pe un anumit atribut.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/600/1*XMId5sJqPtm8-RIwVVz2tg.png)\n",
    "\n",
    "O problemă des intalnita este faptul ca un set mare de caracteristici, rezultă un număr mare de împărțire, care la rândul său conduce la un copac uriaș. Asemenea copaci sunt complexi și pot duce la suprasolicitare. Deci, trebuie să știm când să ne oprim. O modalitate de a face acest lucru este de a stabili un număr minim de intrări de instruire pe fiecare frunză. De exemplu, putem folosi cel puțin 10 pasageri pentru a ajunge la o decizie (a murit sau a supraviețuit) și pentru a ignora orice frunză care ia mai puțin de 10 pasageri. O altă modalitate este de a stabili adâncimea maximă a modelului. Adâncimea maximă se referă la lungimea celei mai lungi căi de la o rădăcină la o frunză.\n",
    "\n",
    "Resurse:\n",
    "1. https://towardsdatascience.com/selecting-the-best-machine-learning-algorithm-for-your-regression-problem-20c330bad4ef\n",
    "2. https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052\n",
    "3. https://scikit-learn.org/stable/modules/tree.html#tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gaussian Process Regression (GPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Process este un algoritm puternic atât pentru regresie, cât și pentru clasificare. Cel mai mare avantaj practic al acestuia este că poate oferi o estimare fiabilă a propriei incertitudini. \n",
    "\n",
    "Gaussian Process Regressor implementează Gaussian Process (GP) în scopuri de regresie. Pentru aceasta, trebuie precizat înainte GP. Media anterioară se presupune a fi constantă și zero (pentru normalize_y = False) sau media datelor de antrenament (pentru normalize_y = True). Co-covarianța precedentului este specificată prin trecerea unui obiect kernel. Hiperparametrele kernel-ului sunt optimizate în timpul montajului GPR prin maximizarea probabilității log-marginale (LML) bazată pe optimizatorul trecut. Deoarece LML poate avea mai multe optimizări locale, optimizatorul poate fi pornit în mod repetat prin specificarea n_restarts_optimizer. Prima rulare se efectuează întotdeauna pornind de la valorile inițiale ale hiperparametrului kernel-ului; etapele următoare sunt efectuate din valorile hiperparametrului care au fost alese aleatoriu din intervalul de valori permise. Dacă hiperparametrele inițiale ar trebui să fie ținute fixe, niciuna nu poate fi trecută ca optimizator.\n",
    "\n",
    "Nivelul de zgomot poate fi specificat prin trecerea acestuia prin parametrul alfa, fie global ca scalar, fie per datapoint. Rețineți că un nivel moderat al zgomotului poate fi, de asemenea, util pentru rezolvarea problemelor numerice în timpul montajului, deoarece este efectiv implementat ca regularizare Tikhonov, adică prin adăugarea acestuia la diagonala matricei kernel-ului. O alternativă la specificarea nivelului de zgomot în mod explicit este includerea unei componente WhiteKernel în kernel, care poate estima nivelul global de zgomot din date.\n",
    "\n",
    "Acest exemplu ilustrează faptul că GPR cu un kernel sum care include un WhiteKernel poate estima nivelul de zgomot al datelor. O ilustrare a peisajului logargin-probabilității (LML) arată că există două maxime locale ale LML.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_gpr_noisy_0001.png)\n",
    "\n",
    "Primul corespunde unui model cu un nivel ridicat al zgomotului și o scală de lungime mare, care explică toate variațiile datelor prin zgomot.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_gpr_noisy_0011.png)\n",
    "\n",
    "Cel de-al doilea are un nivel de zgomot mai mic și o scală de lungime mai scurtă, ceea ce explică cea mai mare parte a variației prin relația funcțională fără zgomot. Cel de-al doilea model are o probabilitate mai mare; totuși, în funcție de valoarea inițială pentru hiperparametrii, optimizarea pe bază de gradient ar putea converge, de asemenea, la soluția cu zgomot ridicat. Este deci important să repetați optimizarea de mai multe ori pentru diferite inițializări.\n",
    "\n",
    "Resurse:\n",
    "1. https://scikit-learn.org/stable/modules/gaussian_process.html\n",
    "2. https://towardsdatascience.com/an-intuitive-guide-to-gaussian-processes-ec2f0b45c71d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
